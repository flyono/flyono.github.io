---
title: 消息中间件
date: 2024-6-10
updated: 2024-6-10
categories: "面试"
tags: 
	- "消息中间件"
	- "八股文"
---

# 消息中间件

- Rabbit MQ
  - 消息不丢失
  - 消息重复消费
  - 消息堆积
  - 延迟队列
  - 死信队列
  - 高可用机制
- Kafka
  - 消息不丢失
  - 消息重复消费
  - 消息堆积
  - 延迟队列
  - 死信队列
  - 高可用机制
  - 高性能设计
  - 数据存储和清理

# Rabbit MQ

## 如何保证消息不丢失

- 异步发送(验证码、短信、邮件...)
- MySQL 和 Redis, ES 之间的数据同步
- 分布式事务
- 削峰填谷

### 生产者确认机制

> ​	RabbitMQ提供了`publisher confirm`机制来避免消息发送到MQ过程中丢失。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功

消息失败之后如何处理呢?

- 回调方法即时重发
- 记录日志
- 保存到数据库中然后定时重发，成功发送后即刻删除表中的数据

### 消息持久化

> ​	MQ默认是内存存储消息, 开启持久化功能可以确保缓冲在MQ中的消息不丢失。

1. 交换机持久化

```java
@Bean
public DirectExchange simpleExchange() {
    // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除
    return new DireExchange("simple.direct", true, false);
}
```

2. 队列持久化

```java
@Bean
public Queue simpleQueue() {
    //使用QueueBuilder构建队列，durable就是持久化的
    return QueueBuilder.durable("simple.queue").build();
}
```

3. 消息持久化, `SpringAMQP`中的消息默认是持久的，可以通过`MessageProperties`中的`DeliveryMode`来指定

```java
Message msg = MessageBuilder
    	.withBody(message.getBytes(StandardCharsets.UTF_8))
    	.setDeliveryMode(MessageDeliveryMode.PERSISTENT)
    	.build();
```

### 消费者确认

> ​	RabbitMQ支持消费者确认机制，即：消费者处理消息后可以向MQ发送ack回执，MQ收到ack回执后才会删除该消息。而`SpringAMQP`则允许配置三种确认模式：
>
> - `manual`：手动ack，需要在业务代码结束后，调用`api`发送`ack`。
> - `auto`：自动ack，由`spring`监测`listener`代码是否出现异常，没有异常则返回`ack`；抛出异常则返回`nack`
> - `none`：关闭ack，MQ 假定消费者获取消息后会成功处理，因此消息投递后立即被删除

​	我们可以利用`Spring`的`retry`机制，在消费者出现异常时利用本地重试，设置重试次数，当次数达到了以后，如果消息依然失败，将消息投递到异常交换机，交由人工处理

### 总结

- 开启生产者确认机制，确保生产者的消息能到达队列
- 开启持久化功能，确保消息未消费前在队列中不会丢失
- 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack
- 开启消费者失败重试机制，多次重试失败后将消息投递到异常交换机，交由人工处理

## 消息的重复消费问题

- 网络抖动
- 消费者挂了

解决方案：适用于任何MQ

- 每条消息设置一个唯一的标识id
- 幂等方案：【分布式锁、数据库锁（悲观锁、乐观锁）】

## Rabbit MQ 死信交换机、延迟队列

> 延迟队列：进入队列的消息会被延迟消费的队列
>
> 场景：
>
> - 超时订单
> - 限时优惠
> - 定时发布
>
> 延迟队列 = 死信交换机 + TTL（生存时间）

### 死信交换机

当一个队列中的消息满足下列情况之一时，可以称为**死信（dead letter）**

- 消费者使用`basic.reject`或`basic.nack`声明消费失败，并且消息的requeue参数设置为false
- 消息是一个过期消息，超时无人消费
- 要投递的队列消息堆积满了，最早的消息可能成为死信

如果该队列`配置了dead-letter-exchange属性`，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为`死信交换机（DeadLetterExchange，简称DLX）`。

```java
@Bean
public Queue ttlQueue() {
	return QueueBuilder.durable("simple.queue")
        .ttl(1000) // 设置队列的超时时间，10s
        .deadLetterExchange("dl.direct") // 指定死信交换机
        .build();
}
```

### TTL

> ​	TTL，也就是`Time-To-Live`。如果一个队列中的消息TTL结束仍未消费，则会变为死信，`ttl`超时分为两种情况：
>
> - 消息所在的队列设置了存活时间
> - 消息本身设置了存活时间

![image-20240610224545081](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240610224545081.png)

### 延迟队列插件

`DelayExchange`插件，需要安装在RabbitMQ中RabbitMQ有一个官方的插件社区，地址为：https://www.rabbitmq.com/community-plugins.html

`DelayExchange`的本质还是官方的三种交换机，只是添加了延迟功能。因此使用时只需要声明一个交换机，交换机的类型可以是任意类型，然后设定delayed属性为true即可。

![image-20240610224716961](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240610224716961.png)

![image-20240610224723791](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240610224723791.png)

## 息堆积怎么解决

RabbitMQ如果有100万消息堆积在MQ，如何解决（消息堆积怎么解决）？

> ​	当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题

解决消息堆积有三种种思路：

- 增加更多消费者，提高消费速度
- 在消费者内开启线程池加快消息处理速度
- 扩大队列容积，提高堆积上限, 采用**惰性队列**

### 惰性队列

> ​	惰性队列的特征如下：
>
> - 接收到消息后直接存入磁盘而非内存
> - 消费者要消费消息时才会从磁盘中读取并加载到内存
> - 支持数百万条的消息存储

- 配置方式

```java
@Bean
public Queue lazyQueue() {
    return QueueBuilder
        .durable("lazy.queue")
        .lazy() // 开启x-queue-mode为lazy
        .build();
}
```

- 注解方式

```java
@RabbitListener(queuesToDeclare = @Queue(
		name = "lazy.queue",
    	durable="true",
    	arguments = @Argument(name = "x-queue-mode", value = "lazy")
))
public void listenLazyQueue(String msg) {
    log.info("接收到 lazy.queue的消息：{}", msg);
}
```

## 高可用机制

RabbitMQ的高可用机制有了解过嘛？

- 在生产环境下，使用集群来保证高可用性
- 普通模式集群
- **镜像模式集群**
- 仲裁模式集群

### 普通集群

> ​	普通集群，或者叫标准集群（classic cluster），具备下列特征：
>
> - 会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。
> - 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回
> - 队列所在节点岩机，队列中的消息就会丢失

### 镜像集群

> ​	镜像集群：本质是主从模式，具备下面的特征：
>
> - 交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。
> - 创建队列的节点被称为该队列的主节点，备份到的其它节点叫做该队列的镜像节点。
> - 一个队列的主节点可能是另一个队列的镜像节点
> - 所有操作都是主节点完成，然后同步给镜像节点
> - 主宕机后，镜像节点会替代成新的主

### 仲裁队列

> ​	仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：
>
> - 与镜像队列一样，都是主从模式，支持主从数据同步
> - 使用非常简单，没有复杂的配置主从同步
> - 基于Raft协议，强一致

```java
@Bean
public Queue quorumQueue() {
    return QueueBuilder
        .durable("quorum.queue") // 持久化
        .quorum() // 仲裁队列
        .build();
}
```

# Kafka

## 如何保证消息不丢失

- 生存者发送到消息到`Brocker`丢失
- 消息在`Brocker`中存储丢失
- 消费者从`Brocker`接受消息丢失

### 生存者发送到消息到`Brocker`丢失

- 设置异步发送

```java
// 同步发送
RecordMetadata recordMetadata = kafkaProducer.send(record).get();
// 异步发送
kafkaProducer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if(e != null) {
            System.out.println("消息发送失败 | 记录日志");
        }
        long offset = recordMetadata.offset();
        int partition = recordMetadata.partition();
        String topic = recordMetadata.topic();
    }
})
```

- 消息重试

```java
// 设置重试次数
prop.put(ProducerConfig.RETRIES_CONFIG, 10);
```

### 消息在`Brocker`中存储丢失

- 发送确认机制`acks`

|   确认机制    | 说明                                                         |
| :-----------: | ------------------------------------------------------------ |
|    acks=0     | 生产者在成功写入消息之前不会等待任何来自服务器的响应，消息有丢失的风险，但是速度最快 |
| ack=1(默认值) | 只有集群首领节点收到消息，生产者就会收到一个来之服务器的成功响应 |
|    ack=all    | 只有当所有参与赋值的节点全部收到消息时，生产者才会受到一个来自服务器的成功响应 |

### 消费者从`Brocker`接受消息丢失

- Kafka 中的分区机制指的是将每个主题划分成多个分区(`Partition`)
- topic 分区中消息只能由消费者组中的唯一一个消费者处理，不同的分区分配给不同的消费者(同一个消费者组)

> ​	消费者默认是自动按期提交已经消费的偏移量，默认是每隔5s提交一次如果出现重平衡的情况，可能会**重复消费**或丢失数据

禁用自动提交偏移量，改为手动

- 同步提交
- 异步提交
- 同步 + 异步组合提交

## 重复消费如何解决

- 关闭自动提交偏移量，并开启手动提交偏移量
- 提交方案，最好是同步+异步提交
- 幂等方案（token + redis 和 分布式锁）

## 如何保证消费的顺序性

应用场景：

- 即时消息中的单对单聊天和群聊，保证发送方消息发送顺序与接收方的顺序一致
- 充值转账两个渠道在同一个时间进行余额变更，短信通知必须要有顺序

问题原因：

> ​	kafka默认存储和消费消息，是不能保证顺序性的，因为一个topic数据可能存储在不同的分区中，每个分区都有一个按照顺序的存储的偏移量，如果消费者关联了多个分区不能保证顺序性

如何解决？

- 发送消息时指定分区号
- 发送消息时按照相同的业务设置相同的`key`

## 高可用机制

- 集群模式
- 分区备份机制

### 集群模式

- Kafka 的服务器端由被称为`Brocker`的服务进程构成，即一个Kafka集群由多个Broker组成
- 这样如果集群中某一台机器宕机，其他机器上的Broker也依然能够对外提供服务。这其实就是Kafka提供高可用的手段之一。

### 分区备份机制

- 一个`topic`有多个分区，每个分区有多个副本，其中有一个`leader`, 其余的是`follower`, 副本存储在不同的`broker`中
- 所有的分区副本的内容都是相同的，如果`leader`发生故障时，会自动将其中一个`follower`提升为`leader`

![image-20240611100955147](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240611100955147.png)

> **ISR（in-syncreplica）需要同步复制保存的follower**

如果leader失效后，需要选出新的leader，选举的原则如下：

- 第一：选举时优先从`ISR`中选定，因为这列表中`follower`的数据是与`leader`同步的
- 第二：如果`ISR`列表中的`follower`都不行了，就只能从其他`follower`中选取

![image-20240611101122582](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240611101122582.png)

## 数据清理机制

### Kafka 存储机制

存储结构：

- flyone
  - 1
    - Segment 0
    - Segment 1
    - Segment 2
  - 2
  - 3

为什么要分段？

- 删除无用文件方便，提高磁盘利用率
- 查找数据便捷

> - Kafka中topic的数据存储在分区上，分区如果文件过大会分段存储segment
> - 每个分段都在磁盘上以索引(`xxxx.index`)和日志文件(`xxxx.log`)的形式存储
> - 分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理。

### 日志的清理策略

1. 根据消息的保留时间，当消息在kafka中保存的时间超过了指定的时间，就会触发清理过程
2. 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值（`1G`），则开始删除最久的消息。需手动开启

> - 根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时（7天）
> - 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。（默认关闭）

## 高性能设计

- **消息分区：不受单台服务器的限制，可以不受限的处理更多的数据**
- **顺序读写：磁盘顺序读写，提升读写效率**
- **页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问**
- **零拷贝：减少上下文切换及数据拷贝**
- 消息压缩：减少磁盘IO和网络IO
- 分批发送：将消息打包批量发送，减少网络开销

### 零拷贝

![image-20240611103537201](https://bed.flyone.space/%E7%AC%94%E8%AE%B0/image-20240611103537201.png)
